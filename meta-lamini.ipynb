{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1es-WIuoFfNwaq2Y7J0W95c3DNECPG3-j","authorship_tag":"ABX9TyMuLuBAw/9whmvTRRonC4pa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Q2mP3nh0IxY","executionInfo":{"status":"ok","timestamp":1719507229938,"user_tz":300,"elapsed":29837,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"c06a3761-f881-4822-c3fc-516a263cf252"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lamini\n","  Downloading lamini-2.5.4-2-py3-none-any.whl (691 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.4/691.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lamini-configuration[yaml] (from lamini)\n","  Downloading lamini_configuration-0.8.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.4)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from lamini) (1.25.2)\n","Collecting jsonlines (from lamini)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (2.0.3)\n","Collecting azure-storage-blob (from lamini)\n","  Downloading azure_storage_blob-12.20.0-py3-none-any.whl (392 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.2/392.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from lamini) (3.9.5)\n","Collecting faiss-cpu (from lamini)\n","  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (4.0.3)\n","Collecting azure-core>=1.28.0 (from azure-storage-blob->lamini)\n","  Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (42.0.8)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (4.12.2)\n","Collecting isodate>=0.6.1 (from azure-storage-blob->lamini)\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu->lamini) (24.1)\n","Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2024.6.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.5.0)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.22)\n","Installing collected packages: lamini-configuration, jsonlines, isodate, faiss-cpu, azure-core, azure-storage-blob, lamini\n","Successfully installed azure-core-1.30.2 azure-storage-blob-12.20.0 faiss-cpu-1.8.0.post1 isodate-0.6.1 jsonlines-4.0.0 lamini-2.5.4 lamini-configuration-0.8.3\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"]}],"source":["%pip install lamini\n","%pip install tabulate"]},{"cell_type":"code","source":["%load_ext sql"],"metadata":{"id":"co-W2IgwKPdk","executionInfo":{"status":"ok","timestamp":1719466066128,"user_tz":300,"elapsed":1384,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","lamini_api_key = userdata.get('LAMINI_API_KEY')\n","print( lamini_api_key)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bq6XEnM30x-t","executionInfo":{"status":"ok","timestamp":1719460418437,"user_tz":300,"elapsed":4701,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"02f4b96a-41e5-46ca-fa9b-e6af9a6982e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2e55706d27dc2125951da4ccde0dcb35496471ae2991db2ac049708ced5608f3\n"]}]},{"cell_type":"code","source":["import lamini\n","lamini.api_key = lamini_api_key\n","llm = lamini.Lamini(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n","print(llm.generate(\"How are you?\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_A6DiX5o096B","executionInfo":{"status":"ok","timestamp":1719463418052,"user_tz":300,"elapsed":4832,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"3b50c30b-4903-41c3-a4e1-2b52ffd569a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you. Take care! How are you? I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you. Take care! How are you? I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you. Take care! How are you? I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you. Take care! How are you? I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you. Take care! How are you? I hope you're doing well. I just wanted to check in and see if you're still interested in the job at [Company Name]. I know it's been a while since we last spoke, but I wanted to follow up and see if you're still available and interested in the position.\n","If you are, I'd be happy to set up a time to talk more about the job and answer any questions you may have. If you're not interested, no worries at all. I just wanted to check in and make sure you're doing well.\n","Let me know either way, and I look forward to hearing back from you.\n"]}]},{"cell_type":"code","source":["import logging\n","import os\n","import random\n","from datetime import datetime\n","from pprint import pprint\n","from typing import AsyncIterator, Iterator, Union\n","import sqlite3\n","import copy\n","from tqdm import tqdm\n","from tabulate import tabulate\n","\n","import pandas as pd\n","import jsonlines\n","from lamini.generation.base_prompt_object import PromptObject\n","from lamini.generation.generation_node import GenerationNode\n","from lamini.generation.base_prompt_object import PromptObject\n","from lamini.generation.generation_pipeline import GenerationPipeline\n","from util.get_schema import get_schema\n","from util.make_llama_3_prompt import make_llama_3_prompt\n","from util.setup_logging import setup_logging\n","from util.load_dataset import get_dataset\n","from util.get_default_finetune_args import get_default_finetune_args\n","\n","logger = logging.getLogger(__name__)\n","engine = sqlite3.connect(\"./nba_roster.db\")\n","setup_logging()\n","\n","class Args:\n","    def __init__(self,\n","                 max_examples=100,\n","                 sql_model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n","                 gold_file_name=\"gold-test-set.jsonl\",\n","                 training_file_name=\"generated_queries.jsonl\",\n","                 num_to_generate=10):\n","        self.sql_model_name = sql_model_name\n","        self.max_examples = max_examples\n","        self.gold_file_name = gold_file_name\n","        self.training_file_name = training_file_name\n","        self.num_to_generate = num_to_generate"],"metadata":{"id":"WubIOOq6D9Lz","executionInfo":{"status":"ok","timestamp":1719465857104,"user_tz":300,"elapsed":278,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n","\n","question = \"\"\"Who is the highest paid NBA player?\"\"\"\n","system = f\"\"\"You are an NBA analyst with 15 years of experience writing complex SQL queries. Consider the nba_roster table with the following schema:\n","{get_schema()}\n","\n","Write a sqlite query to answer the following question. Follow instructions exactly\"\"\"\n","prompt = make_llama_3_prompt(question, system)\n","print(\"Question:\\n\", question)\n","\n","# Ask the model to generate a sql query to answer the question\n","print(\"Answer:\")\n","print(llm.generate(prompt, max_new_tokens=200))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtPHXu7rJuUr","executionInfo":{"status":"ok","timestamp":1719465883702,"user_tz":300,"elapsed":1722,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"7ade1d4b-857d-4a3d-83e9-1e96d11e1690"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Question:\n"," Who is the highest paid NBA player?\n","Answer:\n","To answer this question, we can use the following SQLite query:\n","\n","```sql\n","SELECT NAME, SALARY\n","FROM nba_roster\n","WHERE SALARY!= '--'\n","ORDER BY CAST(SALARY AS REAL) DESC\n","LIMIT 1;\n","```\n","\n","This query first filters out the rows where the salary is '--' (i.e., the players who don't have a salary listed). Then, it orders the remaining rows by the salary in descending order (highest to lowest). Finally, it returns the top row, which corresponds to the highest paid NBA player.\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","\n","sql = \"SELECT NAME, SALARY FROM nba_roster WHERE SALARY!= '--' ORDER BY CAST(SALARY AS REAL) DESC LIMIT 1;\"\n","conn = sqlite3.connect(\"./nba_roster.db\")\n","df = pd.read_sql_query(sql, conn)\n","df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"DCz7q8SVJ69U","executionInfo":{"status":"error","timestamp":1719496560085,"user_tz":300,"elapsed":183,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"5d46a818-2b06-4c16-c7f3-8a9054d78faf"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sqlite3' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7c693be04526>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT NAME, SALARY FROM nba_roster WHERE SALARY!= '--' ORDER BY CAST(SALARY AS REAL) DESC LIMIT 1;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./nba_roster.db\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sqlite3' is not defined"]}]},{"cell_type":"code","source":["class QueryStage(GenerationNode):\n","    def __init__(self, model_name):\n","        super().__init__(\n","            model_name=model_name,\n","            max_new_tokens=150,\n","        )\n","\n","    def generate(\n","        self,\n","        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n","        *args,\n","        **kwargs,\n","    ):\n","        results = super().generate(\n","            prompt,\n","            output_type={\"sqlite_query\": \"str\"},\n","            *args,\n","            **kwargs,\n","        )\n","        return results\n","\n","\n","    def postprocess(self, obj: PromptObject):\n","        # Run both the generated and reference (Gold Dataset) SQL queries\n","        # Assessing whether the SQL queries succeeded in hitting the database (not correctness yet!)\n","\n","        query_succeeded = False\n","\n","        try:\n","            logger.info(f\"Running SQL query '{obj.response['sqlite_query']}'\")\n","            obj.data[\"generated_query\"] = obj.response[\"sqlite_query\"]\n","            df = pd.read_sql(obj.response[\"sqlite_query\"], con=engine)\n","            obj.data['df'] = df\n","            logger.info(f\"Got data: {df}\")\n","            query_succeeded = True\n","\n","        except Exception as e:\n","            logger.error(\n","                f\"Failed to run SQL query: {obj.response['sqlite_query']}\"\n","            )\n","\n","        logger.info(f\"Running reference SQL query '{obj.data['sql']}'\")\n","        df = pd.read_sql(obj.data[\"sql\"], con=engine)\n","        logger.info(f\"Got data: {df}\")\n","        obj.data['reference_df'] = df\n","\n","        logger.info(f\"For question: {obj.data['question']}\")\n","        logger.info(f\"For query: {obj.response['sqlite_query']}\")\n","\n","        obj.data[\"query_succeeded\"] = query_succeeded\n","\n","    def preprocess(self, obj: PromptObject):\n","        new_prompt = make_llama_3_prompt(**self.make_prompt(obj.data))\n","        obj.prompt = new_prompt\n","\n","    def make_prompt(self, data: dict):\n","        system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n","        system += \"Consider the nba_roster table with the following schema:\\n\"\n","        system += get_schema() + \"\\n\"\n","        system += (\n","            \"Write a sqlite SQL query that would help you answer the following question:\\n\"\n","        )\n","        user = data[\"question\"]\n","        return {\n","            \"user\": user,\n","            \"system\": system,\n","        }"],"metadata":{"id":"A9QHuyfoOV-f","executionInfo":{"status":"ok","timestamp":1719467076936,"user_tz":300,"elapsed":289,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["class ScoreStage(GenerationNode):\n","    def __init__(self):\n","        super().__init__(\n","            model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n","            max_new_tokens=150,\n","        )\n","\n","    def generate(\n","        self,\n","        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n","        *args,\n","        **kwargs,\n","    ):\n","        results = super().generate(\n","            prompt,\n","            output_type={\"explanation\": \"str\", \"similar\": \"bool\"},\n","            *args,\n","            **kwargs,\n","        )\n","        return results\n","\n","    def preprocess(self, obj: PromptObject):\n","        obj.prompt = make_llama_3_prompt(**self.make_prompt(obj))\n","        logger.info(f\"Scoring Stage Prompt:\\n{obj.prompt}\")\n","\n","    def postprocess(self, obj: PromptObject):\n","        obj.data['is_matching'] = self.is_matching(obj.data, obj.response)\n","        obj.data['explanation'] = obj.response[\"explanation\"]\n","        obj.data['similar'] = obj.response[\"similar\"]\n","\n","    def is_matching(self, data, response):\n","        return (str(data.get('df',\"None\")).lower() == str(data['reference_df']).lower()\n","                or response['similar'])\n","\n","    def make_prompt(self, obj: PromptObject):\n","        # Your evaluation model compares SQL output from the generated and reference SQL queries, using another LLM in the pipeline\n","        system_prompt = \"Compare the following two dataframes. They are similar if they are almost identical, or if they convey the same information about the nba_roster dataset\"\n","        system_prompt += \"Respond with valid JSON {'explanation' : str, 'similar' : bool}\"\n","        user_prompt = (\n","            f\"========== Dataframe 1 =========\\n{str(obj.data.get('df','None')).lower()}\\n\\n\"\n","        )\n","        user_prompt += (\n","            f\"========== Dataframe 2 =========\\n{str(obj.data['reference_df']).lower()}\\n\\n\"\n","        )\n","        user_prompt += f\"Can you tell me if these dataframes are similar?\"\n","        return {\n","            \"system\": system_prompt,\n","            \"user\": user_prompt\n","        }"],"metadata":{"id":"rO9uNyXYOY2X","executionInfo":{"status":"ok","timestamp":1719467109368,"user_tz":300,"elapsed":316,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["async def run_eval(dataset, args):\n","\n","    results = await run_evaluation_pipeline(dataset, args)\n","\n","    print(\"Total results:\", len(results))\n","\n","    return results\n","\n","\n","async def run_evaluation_pipeline(dataset, args):\n","    results = EvaluationPipeline(args).call(dataset)\n","\n","    result_list = []\n","\n","    pbar = tqdm(desc=\"Saving results\", unit=\" results\")\n","    async for result in results:\n","        result_list.append(result)\n","        pbar.update()\n","    return result_list\n","\n","\n","class EvaluationPipeline(GenerationPipeline):\n","    def __init__(self, args):\n","        super().__init__()\n","        self.query_stage = QueryStage(args.sql_model_name)\n","        self.score_stage = ScoreStage()\n","\n","\n","    def forward(self, x):\n","        x = self.query_stage(x)\n","        x = self.score_stage(x)\n","        return x"],"metadata":{"id":"JUo8AzMLOipN","executionInfo":{"status":"ok","timestamp":1719467128745,"user_tz":300,"elapsed":294,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def load_gold_dataset(args):\n","    path = f\"data/{args.gold_file_name}\"\n","\n","    with jsonlines.open(path) as reader:\n","        for index, obj in enumerate(reversed(list(reader))):\n","            if index >= args.max_examples:\n","                break\n","            yield PromptObject(prompt=\"\", data=obj)"],"metadata":{"id":"U1CECT6GOmQe","executionInfo":{"status":"ok","timestamp":1719467144236,"user_tz":300,"elapsed":287,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def save_eval_results(results, args):\n","    base_path = \"./data/results\"\n","    now = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n","    experiment_name = f\"nba_sql_pipeline_{now}\"\n","    experiment_dir = os.path.join(base_path, experiment_name)\n","    os.makedirs(os.path.join(base_path, experiment_name))\n","\n","    # Write args to file\n","    args_file_name = f\"{experiment_dir}/args.txt\"\n","    with open(args_file_name, \"w\") as writer:\n","        pprint(args.__dict__, writer)\n","\n","\n","    def is_correct(r):\n","        if (\n","            (result.data[\"query_succeeded\"] and result.data['is_matching']) or\n","            result.data[\"generated_query\"] == result.data['sql']\n","        ):\n","            return True\n","        return False\n","\n","    # Write sql results and errors to file\n","    results_file_name = f\"{experiment_dir}/sql_results.jsonl\"\n","    with jsonlines.open(results_file_name, \"w\") as writer:\n","        for result in results:\n","            if not is_correct(result):\n","                continue\n","            writer.write(\n","                {\n","                    \"question\": result.data['question'],\n","                    \"query\": result.data[\"generated_query\"],\n","                    \"query_succeeded\": result.data[\"query_succeeded\"],\n","                    \"reference_sql\": result.data['sql'],\n","                    \"df\": str(result.data.get('df', 'None')),\n","                    \"reference_df\": str(result.data['reference_df']),\n","                    'is_matching': result.data['is_matching'],\n","                    'similar': result.data['similar'],\n","                }\n","            )\n","\n","    results_file_name = f\"{experiment_dir}/sql_errors.jsonl\"\n","    with jsonlines.open(results_file_name, \"w\") as writer:\n","        for result in results:\n","            if is_correct(result):\n","                continue\n","            writer.write(\n","                {\n","                    \"question\": result.data['question'],\n","                    \"query\": result.data[\"generated_query\"],\n","                    \"query_succeeded\": result.data[\"query_succeeded\"],\n","                    \"df\": str(result.data.get('df', 'None')),\n","                    \"reference_df\": str(result.data['reference_df']),\n","                    'is_matching': result.data['is_matching'],\n","                    'similar': result.data['similar'],\n","                }\n","            )\n","\n","    # Write statistics to file\n","    average_sql_succeeded = sum(\n","        [result.data[\"query_succeeded\"] for result in results]\n","    ) / len(results)\n","    average_correct = sum(\n","        [result.data[\"query_succeeded\"] and result.data['is_matching'] for result in results]\n","    ) / len(results)\n","\n","    file_name = f\"{experiment_dir}/summary.txt\"\n","    with open(file_name, \"w\") as writer:\n","        print(f\"Total size of eval dataset: {len(results)}\", file=writer)\n","        print(f\"Total size of eval dataset: {len(results)}\")\n","        print(f\"Percent Valid SQL Syntax: {average_sql_succeeded*100}\", file=writer)\n","        print(f\"Percent Valid SQL Syntax: {average_sql_succeeded*100}\")\n","        print(f\"Percent Correct SQL Query: {average_correct*100}\", file=writer)\n","        print(f\"Percent Correct SQL Query: {average_correct*100}\")"],"metadata":{"id":"y8GbPTPwOnuO","executionInfo":{"status":"ok","timestamp":1719467160766,"user_tz":300,"elapsed":284,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["args = Args()\n","dataset = load_gold_dataset(args)\n","results = await run_eval(dataset, args)\n","save_eval_results(results, args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYMNUOQUOteu","executionInfo":{"status":"ok","timestamp":1719467212253,"user_tz":300,"elapsed":10244,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"cc773c5f-f9d6-43fc-e687-0dd2115c2164"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","Saving results: 0 results [00:00, ? results/s]\u001b[A2024-06-27 05:46:44,574 [ERROR] Failed to run SQL query: SELECT AVG(CAST(SUBSTR(WT, INSTR(WT,'') + 1) AS INTEGER) AS weight FROM nba_roster WHERE WT IS NOT NULL\n","2024-06-27 05:46:44,584 [ERROR] Failed to run SQL query: SELECT AVG(CAST(SUBSTR(WT, INSTR(WT,'') + 1) AS INTEGER) FROM nba_roster WHERE WT!= 'NA';\n","2024-06-27 05:46:44,594 [ERROR] Failed to run SQL query: SELECT PERCENTILE(SALARY, 0.25) FROM nba_roster WHERE SALARY!= '--';\n","2024-06-27 05:46:44,610 [ERROR] Failed to run SQL query: SELECT PERCENTILE(salary, 0.75) FROM (SELECT CAST(SUBSTR(salary, 2) AS INTEGER) AS salary FROM nba_roster WHERE salary!= '--') AS subquery\n","2024-06-27 05:46:44,621 [ERROR] Failed to run SQL query: SELECT PERCENTILE(salary, 0.99) FROM nba_roster WHERE salary IS NOT NULL\n","2024-06-27 05:46:44,647 [ERROR] Failed to run SQL query: SELECT POS, MAX(CAST(SUBSTR(SALARY, 2) AS INTEGER) AS Salary FROM nba_roster WHERE SALARY!= '--' GROUP BY POS\n","2024-06-27 05:46:44,665 [ERROR] Failed to run SQL query: SELECT AVG(CAST(SUBSTRING(HT, 0, INSTR(HT,'')-1) AS INTEGER) FROM nba_roster WHERE HT IS NOT NULL\n","2024-06-27 05:46:44,675 [ERROR] Failed to run SQL query: SELECT AVG(CAST(SUBSTR(HT, 0, INSTR(HT,'')-1) AS INTEGER) FROM nba_roster WHERE HT IS NOT NULL\n","2024-06-27 05:46:44,688 [ERROR] Failed to run SQL query: SELECT AVG(CAST(SUBSTR(SALARY, 2) AS INTEGER) AS avg_salary FROM nba_roster WHERE POS = 'PF' AND SALARY!= '--';\n","\n","Saving results: 1 results [00:03,  3.05s/ results]\u001b[A\n","Saving results: 11 results [00:03,  4.68 results/s]\u001b[A\n","Saving results: 20 results [00:09,  2.00 results/s]"]},{"output_type":"stream","name":"stdout","text":["Total results: 20\n","Total size of eval dataset: 20\n","Percent Valid SQL Syntax: 55.00000000000001\n","Percent Correct SQL Query: 30.0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["class ModelStage(GenerationNode):\n","    def __init__(self):\n","        super().__init__(\n","            model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n","            max_new_tokens=300,\n","        )\n","\n","    def generate(\n","        self,\n","        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n","        *args,\n","        **kwargs,\n","    ):\n","        prompt = self.add_template(prompt)\n","\n","        results = super().generate(\n","            prompt,\n","            output_type={\n","                \"explanation\": \"str\",\n","                \"sql_query_1\": \"str\",\n","                \"sql_query_2\": \"str\",\n","            },\n","            *args,\n","            **kwargs,\n","        )\n","\n","        return results\n","\n","    async def add_template(self, prompts):\n","        async for prompt in prompts:\n","            new_prompt = make_llama_3_prompt(**self.make_prompt(prompt.data))\n","            yield PromptObject(prompt=new_prompt, data=prompt.data)\n","\n","    async def process_results(self, results):\n","        async for result in results:\n","            if result is None:\n","                continue\n","\n","            if result.response is None:\n","                continue\n","\n","            logger.info(\"=====================================\")\n","            logger.info(f\"Generted query 1: {result.response['sql_query_1']}\")\n","            logger.info(f\"Generted query 2: {result.response['sql_query_2']}\")\n","            logger.info(\"=====================================\")\n","\n","            if self.check_sql_query(result.response[\"sql_query_1\"]):\n","                new_result = PromptObject(prompt=\"\", data=copy.deepcopy(result.data))\n","                new_result.data.generated_sql_query = result.response[\"sql_query_1\"]\n","                yield new_result\n","\n","            if self.check_sql_query(result.response[\"sql_query_2\"]):\n","                new_result = PromptObject(prompt=\"\", data=copy.deepcopy(result.data))\n","                new_result.data.generated_sql_query = result.response[\"sql_query_2\"]\n","                yield new_result\n","\n","    def make_prompt(self, data):\n","        system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n","        system += (\n","            \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n","        )\n","        system += get_schema()\n","        system += \"Consider the following questions, and queries used to answer them:\\n\"\n","        for example in data.sample:\n","            system += \"Question: \" + example[\"question\"] + \"\\n\"\n","            system += \"Query: \" + example[\"sql\"] + \"\\n\"\n","\n","        # Important: generate relevant queries to your reference data\n","        # Ideally, close to those that are failing so you can show the model examples of how to do it right!\n","        user = \"Write two queries that are similar but different to those above.\\n\"\n","        user += \"Format the queries as a JSON object, i.e.\\n\"\n","        user += '{ \"explanation\": str, \"sql_query_1\" : str, \"sql_query_2\": str }.\\n'\n","\n","        # Next, use Chain of Thought (CoT) and prompt-engineering to help with generating SQL queries\n","        user += \"First write an explanation of why you decided to write these new queries in about 3-5 sentences, then write valid sqlite SQL queries for each of the 2 new queries. Make sure each query is complete and ends with a ;\\n\"\n","\n","        return {\"system\": system, \"user\": user}\n","\n","    def check_sql_query(self, query):\n","        try:\n","            pd.read_sql(query, con=engine)\n","        except Exception as e:\n","            logger.debug(f\"Error in SQL query: {e}\")\n","            return False\n","\n","        logger.info(f\"SQL query {query} is valid\")\n","\n","        return True"],"metadata":{"id":"LbNHjMzoO45i","executionInfo":{"status":"ok","timestamp":1719467239962,"user_tz":300,"elapsed":298,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class QuestionStage(GenerationNode):\n","    def __init__(self):\n","        super().__init__(\n","            model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n","            max_new_tokens=150,\n","        )\n","\n","    def generate(\n","        self,\n","        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n","        *args,\n","        **kwargs,\n","    ):\n","        results = super().generate(\n","            prompt,\n","            output_type={\n","                \"explanation\": \"str\",\n","                \"question\": \"str\",\n","            },\n","            *args,\n","            **kwargs,\n","        )\n","        return results\n","\n","    def preprocess(self, obj: PromptObject):\n","        new_prompt = make_llama_3_prompt(**self.make_question_prompt(obj.data))\n","        obj.prompt = new_prompt\n","\n","    def make_question_prompt(self, data):\n","        system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n","        system += (\n","            \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n","        )\n","        system += get_schema() + \"\\n\"\n","        system += \"Queries, and questions that they are used to answer:\\n\"\n","        for example in data.sample:\n","            system += \"Query: \" + example[\"sql\"] + \"\\n\"\n","            system += \"Question: \" + example[\"question\"] + \"\\n\"\n","\n","        user = \"Now consider the following query.\\n\"\n","        user += \"Query: \" + data.generated_sql_query + \"\\n\"\n","        user += \"Write a question that this query could be used to answer.\\n\"\n","\n","        # Using Chain of Thought (CoT) again\n","        # This time you can do it programmatically with function calling, so you can easily extract a question out of the JSON object\n","        user += \"Format your response as a JSON object, i.e.\\n\"\n","        user += '{ \"explanation\": str, \"question\": str }.\\n'\n","\n","        user += \"First write an explanation in about 3-5 sentences, then write a one sentence question.\\n\"\n","\n","        return {\"system\": system, \"user\": user}"],"metadata":{"id":"msQaTsdqO_ZO","executionInfo":{"status":"ok","timestamp":1719467273344,"user_tz":300,"elapsed":296,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["async def run_query_gen_pipeline(seed_queries):\n","    return QueryGenPipeline().call(seed_queries)\n","\n","\n","class QueryGenPipeline(GenerationPipeline):\n","    def __init__(self):\n","        super().__init__()\n","        self.model_stage = ModelStage()\n","        self.question_stage = QuestionStage()\n","\n","    def forward(self, x):\n","        x = self.model_stage(x)\n","        x = self.question_stage(x)\n","        return x"],"metadata":{"id":"5bBTliiEPHhA","executionInfo":{"status":"ok","timestamp":1719467284901,"user_tz":300,"elapsed":653,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["all_examples = []\n","\n","\n","async def load_seed_queries(args):\n","    path = f\"data/{args.gold_file_name}\"\n","\n","    with jsonlines.open(path) as reader:\n","        global all_examples\n","\n","        all_examples = [obj for obj in reader]\n","\n","    sample_count = args.num_to_generate\n","    sample_size = 3\n","\n","    random.seed(42)\n","\n","    for i in range(sample_count):\n","        example_sample = ExampleSample(random.sample(all_examples, sample_size), i)\n","\n","        yield PromptObject(prompt=\"\", data=example_sample)\n","\n","\n","class ExampleSample:\n","    def __init__(self, sample, index):\n","        self.sample = sample\n","        self.index = index"],"metadata":{"id":"3S1XPXsgPKCi","executionInfo":{"status":"ok","timestamp":1719467297342,"user_tz":300,"elapsed":553,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["async def save_generation_results(results, args):\n","    path = f\"data/training_data/{args.training_file_name}\"\n","\n","    pbar = tqdm(desc=\"Saving results\", unit=\" results\")\n","    with jsonlines.open(path, \"a\") as writer:\n","\n","        async for result in results:\n","            writer.write(\n","                {\n","                    \"question\": result.response[\"question\"],\n","                    \"sql\": result.data.generated_sql_query,\n","                }\n","            )\n","            pbar.update()\n","\n","        for example in all_examples:\n","            writer.write(example)\n","            pbar.update()"],"metadata":{"id":"sCEOzuMXPNP8","executionInfo":{"status":"ok","timestamp":1719467365592,"user_tz":300,"elapsed":289,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["args = Args()\n","seed_queries = load_seed_queries(args)\n","results = await run_query_gen_pipeline(seed_queries)\n","await save_generation_results(results, args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7UIwyXePeDk","executionInfo":{"status":"ok","timestamp":1719467500347,"user_tz":300,"elapsed":35048,"user":{"displayName":"Sriram Narasimhan","userId":"04154551268175178324"}},"outputId":"6b40f5b8-cbaa-42dd-9529-7efd1cf7012f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","\n","Saving results: 0 results [00:00, ? results/s]\u001b[A\u001b[A\n","\n","Saving results: 1 results [00:34, 34.63s/ results]\u001b[A\u001b[A\n","\n","Saving results: 30 results [00:34,  1.16s/ results]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HtZFzo1JQnXe"},"execution_count":null,"outputs":[]}]}